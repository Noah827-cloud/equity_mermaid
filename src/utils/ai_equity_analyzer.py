#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡æƒç»“æ„AIåˆ†ææ¨¡å—

è¯¥æ¨¡å—æä¾›ä½¿ç”¨å¤§æ¨¡å‹åˆ†æä¸Šä¼ æ–‡ä»¶ä¸­çš„è‚¡æƒç»“æ„ä¿¡æ¯åŠŸèƒ½ï¼Œæ”¯æŒï¼š
1. è§£æExcelç­‰æ–‡ä»¶ä¸­çš„è‚¡ä¸œã€å®æ§äººã€å­å…¬å¸ä¿¡æ¯
2. æ ¹æ®ç”¨æˆ·æç¤ºè¯æŒ‡å¯¼åˆ†æè¿‡ç¨‹
3. ç”Ÿæˆç¬¦åˆå‰ç«¯éœ€è¦çš„è‚¡æƒç»“æ„æ•°æ®æ ¼å¼
"""

import os
import json
import re
import base64
import logging
import pandas as pd
import uuid
from typing import Dict, List, Optional, Any, Tuple

# è®¾ç½®æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥dashscopeåº“
try:
    import dashscope
    from dashscope import Generation
    from dashscope.api_entities.dashscope_response import Message
    DASHSCOPE_AVAILABLE = True
    # è°ƒè¯•ï¼šæ‰“å°dashscopeç‰ˆæœ¬å’Œé…ç½®
    logger.info(f"å·²å¯¼å…¥dashscopeåº“ï¼Œç‰ˆæœ¬: {getattr(dashscope, '__version__', 'æœªçŸ¥')}")
    
    # è®¾ç½®APIå¯†é’¥
    api_key = os.environ.get('DASHSCOPE_API_KEY')
    if api_key and hasattr(dashscope, 'api_key'):
        dashscope.api_key = api_key
        logger.info("å·²ç›´æ¥è®¾ç½®dashscope APIå¯†é’¥")
    
    # æ³¨æ„ï¼šä¸å°è¯•è®¾ç½®ä»»ä½•URLç›¸å…³é…ç½®ï¼Œè®©åº“ä½¿ç”¨é»˜è®¤URL
    # æ‰‹åŠ¨è®¾ç½®URLå¯èƒ½å¯¼è‡´"url error"é—®é¢˜
except ImportError:
    logger.warning("DashScopeåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    DASHSCOPE_AVAILABLE = False

# å¯¼å…¥å…¶ä»–å¿…è¦çš„åº“
import time

def extract_json_from_text(text: str) -> Dict[str, Any]:
    """
    ä»æ–‡æœ¬ä¸­æå–JSONæ•°æ®
    
    Args:
        text: åŒ…å«JSONçš„æ–‡æœ¬
    
    Returns:
        æå–çš„JSONå­—å…¸
    
    Raises:
        ValueError: æ— æ³•ä»æ–‡æœ¬ä¸­æå–æœ‰æ•ˆJSON
    """
    # å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(text.strip())
    except json.JSONDecodeError:
        pass

    # å°è¯•åŒ¹é… ```json ... ``` æˆ– ``` ... ``` æ ¼å¼
    json_match = re.search(r"```(?:json)?\s*({.*?})\s*```", text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass

    # å°è¯•æŸ¥æ‰¾æœ€å¤–å±‚çš„ {...}
    brace_match = re.search(r"({.*})", text, re.DOTALL)
    if brace_match:
        try:
            return json.loads(brace_match.group(1))
        except json.JSONDecodeError:
            pass

    # å¦‚æœéƒ½å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯å¹¶æ˜¾ç¤ºåŸå§‹å†…å®¹
    raise ValueError(f"æ— æ³•ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–JSON:\n{text}")

def read_excel_file(file_content: bytes) -> Optional[pd.DataFrame]:
    """
    è¯»å–Excelæ–‡ä»¶å†…å®¹
    
    Args:
        file_content: æ–‡ä»¶å­—èŠ‚å†…å®¹
    
    Returns:
        è§£æåçš„æ•°æ®æ¡†ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    try:
        # ä½¿ç”¨pandasè¯»å–Excelæ–‡ä»¶
        import io
        excel_file = io.BytesIO(file_content)
        
        # å°è¯•å¤šç§è¯»å–æ–¹å¼
        try:
            df = pd.read_excel(excel_file, engine='openpyxl')
        except Exception:
            # å¦‚æœopenpyxlå¤±è´¥ï¼Œå°è¯•xlrd
            excel_file.seek(0)
            df = pd.read_excel(excel_file, engine='xlrd')
        
        # å°†æ‰€æœ‰åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…æ•°æ®ç±»å‹é—®é¢˜
        df = df.astype(str)
        return df
    except Exception as e:
        logger.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def analyze_equity_with_ai(
    prompt: str,
    file_content: Optional[bytes] = None,
    file_name: Optional[str] = None,
    api_key: Optional[str] = None
) -> Tuple[Dict[str, Any], List[str]]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åˆ†æè‚¡æƒç»“æ„ä¿¡æ¯
    
    Args:
        prompt: ç”¨æˆ·æç¤ºè¯ï¼Œè¯´æ˜è‚¡ä¸œå…³ç³»è®¾ç½®è¦æ±‚
        file_content: ä¸Šä¼ æ–‡ä»¶çš„å­—èŠ‚å†…å®¹
        file_name: æ–‡ä»¶å
        api_key: DashScope APIå¯†é’¥
    
    Returns:
        Tuple[è‚¡æƒç»“æ„æ•°æ®å­—å…¸, é”™è¯¯æ—¥å¿—åˆ—è¡¨]
    """
    error_logs = []
    equity_data = {
        "core_company": "",
        "actual_controller": "",
        "top_level_entities": [],
        "all_entities": [],
        "subsidiaries": [],
        "entity_relationships": []
    }
    
    try:
        # å‡†å¤‡åˆ†ææç¤ºè¯
        analysis_prompt = f"""
        è¯·åˆ†æä»¥ä¸‹è‚¡æƒç»“æ„ä¿¡æ¯ï¼Œå¹¶æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡ºJSONæ•°æ®ã€‚
        
        ç”¨æˆ·éœ€æ±‚è¯´æ˜:
        {prompt}
        
        è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æ:
        1. ç¡®å®šæ ¸å¿ƒå…¬å¸åç§°å’Œå®é™…æ§åˆ¶äºº
        2. è¯†åˆ«é¡¶çº§å®ä½“/è‚¡ä¸œåŠå…¶æŒè‚¡æ¯”ä¾‹
        3. è¯†åˆ«å­å…¬å¸åŠå…¶æŒè‚¡å…³ç³»
        4. åˆ†æå®ä½“é—´çš„å…³ç³»ï¼Œç‰¹åˆ«æ˜¯æ§è‚¡å…³ç³»å’Œè™šæ‹Ÿå…³ç³»
        
        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹:
        {{
            "core_company": "æ ¸å¿ƒå…¬å¸åç§°",
            "actual_controller": "å®é™…æ§åˆ¶äºº",
            "top_level_entities": [
                {{
                    "name": "è‚¡ä¸œåç§°",
                    "percentage": æŒè‚¡æ¯”ä¾‹æ•°å­—,
                    "entity_type": "è‚¡ä¸œç±»å‹ï¼ˆè‡ªç„¶äºº/æ³•äººï¼‰"
                }}
            ],
            "subsidiaries": [
                {{
                    "name": "å­å…¬å¸åç§°",
                    "parent_entity": "æ¯å…¬å¸åç§°",
                    "percentage": æŒè‚¡æ¯”ä¾‹æ•°å­—
                }}
            ],
            "entity_relationships": [
                {{
                    "from": "å®ä½“Aåç§°",
                    "to": "å®ä½“Båç§°",
                    "relationship_type": "å…³ç³»ç±»å‹",
                    "description": "å…³ç³»æè¿°"
                }}
            ]
        }}
        """
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨çœŸå®API
        use_real_api = DASHSCOPE_AVAILABLE and api_key
        
        if use_real_api:
            logger.info("ä½¿ç”¨çœŸå®APIè¿›è¡Œè‚¡æƒç»“æ„åˆ†æ")
            
            # è®¾ç½®APIå¯†é’¥
            dashscope.api_key = api_key
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": [
                        {
                            "text": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„è‚¡æƒç»“æ„åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æ–‡ä»¶å’Œæ–‡æœ¬ä¸­æå–å…¬å¸è‚¡æƒå…³ç³»ä¿¡æ¯ã€‚"
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": []
                }
            ]
            
            # æ·»åŠ ç”¨æˆ·æç¤ºæ–‡æœ¬
            messages[1]["content"].append({
                "text": analysis_prompt
            })
            
            # å¦‚æœæœ‰æ–‡ä»¶ï¼Œé‡‡ç”¨çº¯æ–‡æœ¬æ–¹å¼å¤„ç†
            if file_content and file_name:
                file_extension = file_name.split('.')[-1].lower() if '.' in file_name else ''
                
                try:
                    logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_name} (å¤§å°: {len(file_content)/1024:.2f}KB)")
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
                    max_file_size_mb = 10
                    if len(file_content) > max_file_size_mb * 1024 * 1024:
                        error_logs.append(f"è­¦å‘Šï¼šæ–‡ä»¶å¤§å°è¶…è¿‡{max_file_size_mb}MBé™åˆ¶")
                        logger.warning(f"æ–‡ä»¶å¤ªå¤§: {len(file_content) / (1024*1024):.2f}MB")
                    
                    # ç›´æ¥ä½¿ç”¨æ–‡æœ¬æ–¹å¼å¤„ç†Excelæ–‡ä»¶
                    if file_extension in ['xlsx', 'xls']:
                        logger.info("å¤„ç†Excelæ–‡ä»¶ï¼Œä½¿ç”¨pandasè¯»å–å†…å®¹")
                        df = read_excel_file(file_content)
                        if df is not None:
                            # é™åˆ¶æ˜¾ç¤ºè¡Œæ•°ï¼Œé¿å…å†…å®¹è¿‡å¤š
                            max_rows = 50
                            if len(df) > max_rows:
                                file_description = f"Excelæ–‡ä»¶'{file_name}'å†…å®¹(å‰{max_rows}è¡Œï¼Œå…±{len(df)}è¡Œ):\n"
                                df = df.head(max_rows)
                            else:
                                file_description = f"Excelæ–‡ä»¶'{file_name}'å†…å®¹:\n"
                            
                            # å°†Excelå†…å®¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ·»åŠ åˆ°æç¤ºä¸­
                            excel_text = df.to_string(index=False)
                            # é™åˆ¶æ–‡æœ¬é•¿åº¦
                            max_text_length = 10000
                            if len(excel_text) > max_text_length:
                                excel_text = excel_text[:max_text_length] + "\n...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
                            
                            messages[1]["content"][0]["text"] += f"\n\n{file_description}{excel_text}"
                            logger.info("æˆåŠŸå°†Excelæ–‡ä»¶å†…å®¹è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼å¹¶æ·»åŠ åˆ°æç¤ºä¸­")
                        else:
                            error_logs.append("è­¦å‘Šï¼šæ— æ³•è¯»å–Excelæ–‡ä»¶å†…å®¹")
                            logger.error("æ— æ³•è¯»å–Excelæ–‡ä»¶")
                    # å¯¹äºæ–‡æœ¬ç±»æ–‡ä»¶ï¼Œç›´æ¥è§£ç 
                    elif file_extension in ['txt', 'csv']:
                        try:
                            text_content = file_content.decode('utf-8', errors='replace')
                            # é™åˆ¶æ–‡æœ¬é•¿åº¦
                            max_text_length = 10000
                            if len(text_content) > max_text_length:
                                text_content = text_content[:max_text_length] + "\n...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
                            
                            messages[1]["content"][0]["text"] += f"\n\næ–‡ä»¶'{file_name}'å†…å®¹:\n{text_content}"
                            logger.info("æˆåŠŸå°†æ–‡æœ¬æ–‡ä»¶å†…å®¹æ·»åŠ åˆ°æç¤ºä¸­")
                        except Exception as decode_error:
                            error_msg = f"æ— æ³•è§£ç æ–‡æœ¬æ–‡ä»¶: {str(decode_error)}"
                            error_logs.append(error_msg)
                            logger.error(error_msg)
                    else:
                        # å¯¹äºå…¶ä»–ç±»å‹çš„æ–‡ä»¶ï¼Œå°è¯•ç®€å•æè¿°
                        error_logs.append(f"è­¦å‘Šï¼šä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ '{file_extension}'ï¼Œå°†å°è¯•æ–‡æœ¬è½¬æ¢")
                        logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}")
                        
                        # å°è¯•ä½œä¸ºäºŒè¿›åˆ¶æ–‡ä»¶æè¿°
                        messages[1]["content"][0]["text"] += f"\n\næ”¶åˆ°æ–‡ä»¶ '{file_name}'ï¼Œå¤§å°: {len(file_content)/1024:.2f}KBï¼Œç±»å‹: {file_extension}"
                        
                        # å°è¯•è§£ç ä¸ºæ–‡æœ¬ä½œä¸ºå›é€€
                        try:
                            text_content = file_content.decode('utf-8', errors='replace')[:2000]
                            messages[1]["content"][0]["text"] += f"\næ–‡ä»¶å†…å®¹é¢„è§ˆ:\n{text_content}\n..."
                        except:
                            pass
                except Exception as e:
                    error_msg = f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                    error_logs.append(error_msg)
                    logger.error(error_msg)
                    # å¤±è´¥æ—¶æ·»åŠ åŸºæœ¬æ–‡ä»¶ä¿¡æ¯
                    messages[1]["content"][0]["text"] += f"\n\næ”¶åˆ°æ–‡ä»¶ '{file_name}'ï¼Œä½†å¤„ç†å¤±è´¥: {str(e)}"
            
            # è°ƒç”¨å¤§æ¨¡å‹
            # å¯¹äºåŒ…å«æ–‡ä»¶çš„è¯·æ±‚ï¼Œè€ƒè™‘ä½¿ç”¨æ›´é€‚åˆå¤šæ¨¡æ€å†…å®¹çš„æ¨¡å‹
            model_to_use = "qwen3-max"
            if file_content and file_name and file_name.split('.')[-1].lower() in ['jpg', 'jpeg', 'png']:
                model_to_use = "qwen3-vl-plus"  # å¯¹äºå›¾ç‰‡æ–‡ä»¶ï¼Œä½¿ç”¨è§†è§‰æ¨¡å‹
                
            logger.info(f"å‡†å¤‡è°ƒç”¨æ¨¡å‹: {model_to_use}")
            
            # ç®€åŒ–æ¶ˆæ¯ç»“æ„ï¼Œä½¿ç”¨æœ€åŸºæœ¬çš„æ ¼å¼
            # å®Œå…¨é¿å…å¤æ‚çš„å¤šæ¨¡æ€ç»“æ„ï¼Œåªä½¿ç”¨ç®€å•çš„æ–‡æœ¬æ¶ˆæ¯
            basic_messages = []
            for msg in messages:
                # æå–çº¯æ–‡æœ¬å†…å®¹
                content = msg["content"]
                if isinstance(content, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
                    text_content = ""
                    for item in content:
                        if isinstance(item, dict) and "text" in item:
                            text_content = item["text"]
                            break
                    basic_messages.append({
                        "role": msg["role"],
                        "content": text_content
                    })
                else:
                    # å¦‚æœæ˜¯ç®€å•æ–‡æœ¬ï¼Œç›´æ¥ä½¿ç”¨
                    basic_messages.append({
                        "role": msg["role"],
                        "content": content
                    })
            
            try:
                # ç›´æ¥è®¾ç½®APIå¯†é’¥ï¼ˆå¦‚æœæœªè®¾ç½®ï¼‰
                if hasattr(dashscope, 'api_key'):
                    api_key = os.environ.get('DASHSCOPE_API_KEY')
                    if api_key:
                        dashscope.api_key = api_key
                        logger.info("å·²ç›´æ¥è®¾ç½®dashscope APIå¯†é’¥")
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œæ£€æŸ¥dashscopeé…ç½®
                logger.info(f"Dashscopeé…ç½®æ£€æŸ¥ - APIå¯†é’¥å·²è®¾ç½®: {hasattr(dashscope, 'api_key') and bool(dashscope.api_key)}")
                
                # å°è¯•ä½¿ç”¨ä¸åŒçš„è°ƒç”¨æ–¹å¼
                # ä¸€äº›ç‰ˆæœ¬çš„dashscopeå¯èƒ½éœ€è¦ä¸åŒçš„å‚æ•°æˆ–æ ¼å¼
                logger.info("å°è¯•ä½¿ç”¨åŸºæœ¬æ¶ˆæ¯æ ¼å¼è°ƒç”¨æ¨¡å‹")
                logger.info(f"æ¨¡å‹: {model_to_use}, æ¶ˆæ¯æ•°é‡: {len(basic_messages)}")
                
                try:
                    # ä½¿ç”¨Generation.call - çº¯æ–‡æœ¬æ¥å£
                    # æ³¨æ„ï¼šä¸ä¼ é€’ä»»ä½•URLç›¸å…³å‚æ•°ï¼Œè®©åº“ä½¿ç”¨é»˜è®¤é…ç½®
                    response = Generation.call(
                        model=model_to_use,
                        messages=basic_messages,
                        temperature=0.01,  # ä½æ¸©åº¦ä»¥ç¡®ä¿ç¡®å®šæ€§è¾“å‡º
                        seed=12345
                    )
                except Exception as call_error:
                    logger.error(f"ç¬¬ä¸€æ¬¡è°ƒç”¨å¤±è´¥: {str(call_error)}")
                    # å¦‚æœä¸»è¦è°ƒç”¨å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                    logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {str(call_error)}")
                    raise call_error  # é‡æ–°æŠ›å‡ºåŸå§‹é”™è¯¯
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code != 200:
                    error_logs.append(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
                    logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
                    # å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
                    use_real_api = False
                else:
                    logger.info("APIè°ƒç”¨æˆåŠŸï¼Œæ­£åœ¨è§£æå“åº”")
                    # è§£ææ¨¡å‹è¾“å‡º
                    try:
                        text_output = ""
                        if hasattr(response, 'output') and hasattr(response.output, 'choices') and response.output.choices:
                            if hasattr(response.output.choices[0], 'message') and hasattr(response.output.choices[0].message, 'content'):
                                contents = response.output.choices[0].message.content
                                if isinstance(contents, str):
                                    # å¦‚æœcontentæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                                    text_output = contents.strip()
                                elif isinstance(contents, list):
                                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
                                    for item in contents:
                                        if isinstance(item, dict) and item.get("text"):
                                            text_output = item["text"].strip()
                                            break
                                else:
                                    # å°è¯•å°†å†…å®¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                                    text_output = str(contents).strip()
                        
                        if not text_output:
                            raise ValueError("æ¨¡å‹è¿”å›ä¸ºç©ºæˆ–æ ¼å¼å¼‚å¸¸")
                        
                        # æå–JSONæ•°æ®
                        extracted_data = extract_json_from_text(text_output)
                        
                        # éªŒè¯å’Œè½¬æ¢æ•°æ®æ ¼å¼
                        equity_data = validate_and_convert_equity_data(extracted_data, error_logs)
                        
                    except Exception as e:
                        error_logs.append(f"è§£ææ¨¡å‹è¾“å‡ºå¤±è´¥: {str(e)}")
                        logger.error(f"è§£æå“åº”å¤±è´¥: {str(e)}")
                        use_real_api = False
            except Exception as e:
                # æ•è·APIè°ƒç”¨è¿‡ç¨‹ä¸­çš„æ‰€æœ‰å¼‚å¸¸
                error_msg = f"æ¨¡å‹è°ƒç”¨å¼‚å¸¸: {str(e)}"
                error_logs.append(error_msg)
                logger.error(error_msg)
                use_real_api = False
        
        # å¦‚æœä¸ä½¿ç”¨çœŸå®APIæˆ–APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ
        if not use_real_api:
            logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆè‚¡æƒç»“æ„")
            equity_data = generate_mock_equity_data(prompt, file_name, error_logs)
        
        # ç¡®ä¿æ•°æ®å®Œæ•´æ€§
        equity_data = ensure_data_completeness(equity_data)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = generate_analysis_report(equity_data)
        equity_data['report'] = report
        
        logger.info(f"è‚¡æƒç»“æ„åˆ†æå®Œæˆï¼Œè¯†åˆ«åˆ° {len(equity_data['top_level_entities'])} ä¸ªé¡¶çº§å®ä½“å’Œ {len(equity_data['subsidiaries'])} ä¸ªå­å…¬å¸")
        
    except Exception as e:
        error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        error_logs.append(error_msg)
        
        # å³ä½¿å‡ºé”™ä¹Ÿç”ŸæˆåŸºæœ¬æŠ¥å‘Š
        if 'equity_data' in locals():
            report = generate_analysis_report(equity_data)
            equity_data['report'] = report
    
    # ç¡®ä¿equity_dataå­˜åœ¨å¹¶åŒ…å«reportå­—æ®µ
    if 'equity_data' not in locals():
        equity_data = {}
    if 'report' not in equity_data:
        equity_data['report'] = "æœªèƒ½ç”Ÿæˆåˆ†ææŠ¥å‘Š"
    
    return equity_data, error_logs

def validate_and_convert_equity_data(data: Dict[str, Any], error_logs: List[str]) -> Dict[str, Any]:
    """
    éªŒè¯å¹¶è½¬æ¢è‚¡æƒæ•°æ®æ ¼å¼
    
    Args:
        data: ä»å¤§æ¨¡å‹æå–çš„æ•°æ®
        error_logs: é”™è¯¯æ—¥å¿—åˆ—è¡¨
    
    Returns:
        éªŒè¯åçš„è‚¡æƒæ•°æ®
    """
    validated_data = {
        "core_company": data.get("core_company", ""),
        "actual_controller": data.get("actual_controller", ""),
        "top_level_entities": [],
        "all_entities": [],
        "subsidiaries": [],
        "entity_relationships": [],
        "control_relationships": []  # æ·»åŠ æ§åˆ¶å…³ç³»åˆ—è¡¨
    }
    
    # éªŒè¯å’Œè½¬æ¢é¡¶çº§å®ä½“
    if "top_level_entities" in data:
        for idx, entity in enumerate(data["top_level_entities"]):
            try:
                # æå–æŒè‚¡æ¯”ä¾‹
                percentage = entity.get("percentage", 0)
                if isinstance(percentage, str):
                    # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                    match = re.search(r'\d+(?:\.\d+)?', percentage)
                    if match:
                        percentage = float(match.group())
                    else:
                        percentage = 0
                
                # éªŒè¯æ•°æ®
                if not entity.get("name"):
                    error_logs.append(f"é¡¶çº§å®ä½“ #{idx+1} ç¼ºå°‘åç§°")
                    continue
                
                if percentage < 0 or percentage > 100:
                    error_logs.append(f"é¡¶çº§å®ä½“ {entity.get('name')} çš„æŒè‚¡æ¯”ä¾‹ {percentage} è¶…å‡ºèŒƒå›´")
                    percentage = max(0, min(100, percentage))
                
                # åˆ›å»ºå®ä½“å¯¹è±¡
                validated_entity = {
                    "name": entity.get("name").strip(),
                    "percentage": float(percentage),
                    "entity_type": entity.get("entity_type", "æœªçŸ¥")
                }
                
                validated_data["top_level_entities"].append(validated_entity)
                validated_data["all_entities"].append(validated_entity)
                
            except Exception as e:
                error_logs.append(f"å¤„ç†é¡¶çº§å®ä½“ #{idx+1} æ—¶å‡ºé”™: {str(e)}")
    
    # éªŒè¯å’Œè½¬æ¢å­å…¬å¸
    if "subsidiaries" in data:
        for idx, sub in enumerate(data["subsidiaries"]):
            try:
                # æå–æŒè‚¡æ¯”ä¾‹
                percentage = sub.get("percentage", 0)
                if isinstance(percentage, str):
                    # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                    match = re.search(r'\d+(?:\.\d+)?', percentage)
                    if match:
                        percentage = float(match.group())
                    else:
                        percentage = 0
                
                # éªŒè¯æ•°æ®
                if not sub.get("name"):
                    error_logs.append(f"å­å…¬å¸ #{idx+1} ç¼ºå°‘åç§°")
                    continue
                
                if percentage < 0 or percentage > 100:
                    error_logs.append(f"å­å…¬å¸ {sub.get('name')} çš„æŒè‚¡æ¯”ä¾‹ {percentage} è¶…å‡ºèŒƒå›´")
                    percentage = max(0, min(100, percentage))
                
                # åˆ›å»ºå­å…¬å¸å¯¹è±¡
                validated_sub = {
                    "name": sub.get("name").strip(),
                    "parent_entity": sub.get("parent_entity", validated_data["core_company"]),
                    "percentage": float(percentage)
                }
                
                validated_data["subsidiaries"].append(validated_sub)
                
            except Exception as e:
                error_logs.append(f"å¤„ç†å­å…¬å¸ #{idx+1} æ—¶å‡ºé”™: {str(e)}")
    
    # éªŒè¯å’Œè½¬æ¢å®ä½“å…³ç³»
    if "entity_relationships" in data:
        # åˆ›å»ºå­å…¬å¸åç§°é›†åˆï¼Œç”¨äºå¿«é€Ÿæ£€æŸ¥
        subsidiary_names = set()
        if data.get("subsidiaries"):
            for sub in data["subsidiaries"]:
                if sub.get("name"):
                    subsidiary_names.add(sub.get("name").strip())
        
        for idx, rel in enumerate(data["entity_relationships"]):
            try:
                if not rel.get("from") or not rel.get("to"):
                    error_logs.append(f"å®ä½“å…³ç³» #{idx+1} ç¼ºå°‘å¿…è¦çš„å®ä½“ä¿¡æ¯")
                    continue
                
                from_entity = rel.get("from").strip()
                to_entity = rel.get("to").strip()
                rel_type = rel.get("relationship_type", "å…³è”")
                
                # é¿å…é‡å¤æ·»åŠ æ§è‚¡å…³ç³»ï¼šå¦‚æœæ˜¯æ ¸å¿ƒå…¬å¸å¯¹å­å…¬å¸çš„æ§è‚¡å…³ç³»ï¼Œä¸”è¯¥å­å…¬å¸å·²åœ¨subsidiariesä¸­ï¼Œåˆ™è·³è¿‡
                if (from_entity == validated_data["core_company"] and 
                    to_entity in subsidiary_names and 
                    ("æ§è‚¡" in rel_type or "æŒæœ‰" in rel_type or "100%" in rel.get("description", ""))):
                    logger.info(f"è·³è¿‡é‡å¤çš„æ§è‚¡å…³ç³»: {from_entity} -> {to_entity}")
                    continue
                
                validated_rel = {
                    "from": from_entity,
                    "to": to_entity,
                    "relationship_type": rel_type,
                    "description": rel.get("description", "")
                }
                
                validated_data["entity_relationships"].append(validated_rel)
                
            except Exception as e:
                error_logs.append(f"å¤„ç†å®ä½“å…³ç³» #{idx+1} æ—¶å‡ºé”™: {str(e)}")
    
    # ğŸ”¥ å–æ¶ˆè‡ªåŠ¨æ·»åŠ å®æ§äººåˆ°æ§åˆ¶å…³ç³» - è®©ç”¨æˆ·æ‰‹åŠ¨æ§åˆ¶
    # æ³¨é‡Šæ‰è‡ªåŠ¨ç”Ÿæˆæ§åˆ¶å…³ç³»çš„ä»£ç 
    # if validated_data["actual_controller"] and validated_data["core_company"]:
    #     # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„æ§åˆ¶å…³ç³»
    #     exists = False
    #     for rel in validated_data.get("control_relationships", []):
    #         if (rel.get("parent") == validated_data["actual_controller"] and 
    #             rel.get("child") == validated_data["core_company"]):
    #             exists = True
    #             break
    #     
    #     # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æ·»åŠ æ–°çš„æ§åˆ¶å…³ç³»
    #     if not exists:
    #         control_rel = {
    #             "parent": validated_data["actual_controller"],
    #             "child": validated_data["core_company"],
    #             "relationship_type": "å®é™…æ§åˆ¶",
    #             "description": f"{validated_data['actual_controller']}æ˜¯{validated_data['core_company']}çš„å®é™…æ§åˆ¶äºº"
    #         }
    #         validated_data["control_relationships"].append(control_rel)
    
    return validated_data

def generate_mock_equity_data(prompt: str, file_name: Optional[str], error_logs: List[str]) -> Dict[str, Any]:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„è‚¡æƒæ•°æ®ï¼Œä¼˜å…ˆä»æµ‹è¯•ç»“æœç›®å½•åŠ è½½çœŸå®æµ‹è¯•æ•°æ®
    
    Args:
        prompt: ç”¨æˆ·æç¤ºè¯
        file_name: æ–‡ä»¶å
        error_logs: é”™è¯¯æ—¥å¿—åˆ—è¡¨
    
    Returns:
        æ¨¡æ‹Ÿçš„è‚¡æƒæ•°æ®
    """
    error_logs.append("ä½¿ç”¨æµ‹è¯•æ•°æ®ï¼Œå®é™…éƒ¨ç½²æ—¶è¯·é…ç½®æœ‰æ•ˆçš„APIå¯†é’¥")
    
    # å°è¯•ä»test_resultsç›®å½•åŠ è½½çœŸå®æµ‹è¯•æ•°æ®
    test_results_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'test_results')
    
    # æµ‹è¯•æ•°æ®æ–‡ä»¶åˆ—è¡¨
    test_files = [
        os.path.join(test_results_dir, 'result_1_ç¦å»ºå—æ–¹è·¯é¢æœºæ¢°è‚¡ä»½æœ‰é™å…¬å¸-å¯¹å¤–æŠ•èµ„-20250930110317.json'),
        os.path.join(test_results_dir, 'result_2_ç¦å»ºå—æ–¹è·¯é¢æœºæ¢°è‚¡ä»½æœ‰é™å…¬å¸-è‚¡ä¸œä¿¡æ¯æœ€æ–°å…¬ç¤º-20250930090121.json')
    ]
    
    # æ ¹æ®æ–‡ä»¶åé€‰æ‹©åˆé€‚çš„æµ‹è¯•æ•°æ®
    selected_file = None
    if file_name:
        # å¦‚æœæ–‡ä»¶ååŒ…å«ç‰¹å®šå…³é”®è¯ï¼Œé€‰æ‹©å¯¹åº”çš„æµ‹è¯•æ•°æ®
        if any(keyword in file_name for keyword in ['æŠ•èµ„', 'å¯¹å¤–']):
            selected_file = test_files[0]  # å¯¹å¤–æŠ•èµ„æ•°æ®
        elif any(keyword in file_name for keyword in ['è‚¡ä¸œ', 'è‚¡æƒ']):
            selected_file = test_files[1]  # è‚¡ä¸œä¿¡æ¯æ•°æ®
    
    # å¦‚æœæ²¡æœ‰æ ¹æ®æ–‡ä»¶åé€‰æ‹©ï¼Œå°è¯•éšæœºé€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶
    if not selected_file and test_files:
        selected_file = test_files[0]  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ª
    
    # å°è¯•åŠ è½½æµ‹è¯•æ•°æ®æ–‡ä»¶
    if selected_file and os.path.exists(selected_file):
        try:
            logger.info(f"åŠ è½½æµ‹è¯•æ•°æ®æ–‡ä»¶: {selected_file}")
            with open(selected_file, 'r', encoding='utf-8') as f:
                test_data = json.load(f)
            
            # æå–è‚¡æƒæ•°æ®éƒ¨åˆ†
            if 'equity_data' in test_data:
                equity_data = test_data['equity_data']
                logger.info(f"æˆåŠŸåŠ è½½æµ‹è¯•æ•°æ®ï¼ŒåŒ…å« {len(equity_data.get('top_level_entities', []))} ä¸ªé¡¶çº§å®ä½“")
                # ç¡®ä¿è¿”å›çš„æ•°æ®ç»“æ„å®Œæ•´
                return ensure_data_completeness(equity_data)
        except Exception as e:
            error_msg = f"åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {str(e)}"
            error_logs.append(error_msg)
            logger.error(error_msg)
    else:
        logger.warning(f"æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {selected_file}")
    
    # å¦‚æœåŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå›é€€
    logger.info("ä½¿ç”¨ç¡¬ç¼–ç æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå›é€€")
    mock_data = {
        "core_company": "ç¤ºä¾‹ç§‘æŠ€æœ‰é™å…¬å¸",
        "actual_controller": "å¼ ä¸‰",
        "top_level_entities": [
            {"name": "å¼ ä¸‰", "percentage": 45.0, "entity_type": "è‡ªç„¶äºº"},
            {"name": "æå››", "percentage": 25.0, "entity_type": "è‡ªç„¶äºº"},
            {"name": "æŠ•èµ„æœºæ„A", "percentage": 20.0, "entity_type": "æ³•äºº"},
            {"name": "æŠ•èµ„æœºæ„B", "percentage": 10.0, "entity_type": "æ³•äºº"}
        ],
        "all_entities": [
            {"name": "å¼ ä¸‰", "percentage": 45.0, "entity_type": "è‡ªç„¶äºº"},
            {"name": "æå››", "percentage": 25.0, "entity_type": "è‡ªç„¶äºº"},
            {"name": "æŠ•èµ„æœºæ„A", "percentage": 20.0, "entity_type": "æ³•äºº"},
            {"name": "æŠ•èµ„æœºæ„B", "percentage": 10.0, "entity_type": "æ³•äºº"}
        ],
        "subsidiaries": [
            {"name": "å­å…¬å¸A", "parent_entity": "ç¤ºä¾‹ç§‘æŠ€æœ‰é™å…¬å¸", "percentage": 80.0},
            {"name": "å­å…¬å¸B", "parent_entity": "ç¤ºä¾‹ç§‘æŠ€æœ‰é™å…¬å¸", "percentage": 60.0}
        ],
        "entity_relationships": [
            {"from": "å¼ ä¸‰", "to": "æå››", "relationship_type": "åˆä½œä¼™ä¼´", "description": "å…±åŒåˆ›å§‹äºº"}
        ]
    }
    
    # å¦‚æœæç¤ºè¯ä¸­æåˆ°ç‰¹å®šå†…å®¹ï¼Œè°ƒæ•´æ¨¡æ‹Ÿæ•°æ®
    if "æ§è‚¡" in prompt or "æ§åˆ¶" in prompt:
        mock_data["actual_controller"] = "ä¸»è¦æ§è‚¡æ–¹"
    
    if "è™šæ‹Ÿå…³ç³»" in prompt:
        mock_data["entity_relationships"].append(
            {"from": "æŠ•èµ„æœºæ„A", "to": "æŠ•èµ„æœºæ„B", "relationship_type": "è™šæ‹Ÿå…³ç³»", "description": "æˆ˜ç•¥åˆä½œ"}
        )
    
    return mock_data

def ensure_data_completeness(data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç¡®ä¿è‚¡æƒæ•°æ®çš„å®Œæ•´æ€§
    
    Args:
        data: è‚¡æƒæ•°æ®
    
    Returns:
        å®Œæ•´çš„è‚¡æƒæ•°æ®
    """
    # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„é”®å­˜åœ¨
    required_keys = [
        "core_company", "actual_controller", "top_level_entities", 
        "all_entities", "subsidiaries", "entity_relationships", "control_relationships"
    ]
    
    for key in required_keys:
        if key not in data:
            if key == "all_entities" and "top_level_entities" in data and data["top_level_entities"]:
                # ç›´æ¥åˆå§‹åŒ–all_entitiesä¸ºtop_level_entitiesçš„å‰¯æœ¬
                data[key] = data["top_level_entities"].copy()
            else:
                data[key] = [] if key.endswith('ies') or key.endswith('s') else ""    
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå–æ¶ˆè‡ªåŠ¨åˆ›å»ºä¸ªäººè‚¡ä¸œä¸æ ¸å¿ƒå…¬å¸çš„è‚¡æƒå…³ç³»
    # è®©ç”¨æˆ·æ‰‹åŠ¨æ§åˆ¶æ‰€æœ‰å…³ç³»ï¼Œé¿å…è‡ªåŠ¨ç”Ÿæˆç”¨æˆ·å·²åˆ é™¤çš„å…³ç³»
    # æ³¨é‡Šæ‰è‡ªåŠ¨ç”Ÿæˆè‚¡æƒå…³ç³»çš„ä»£ç 
    # if data["core_company"] and isinstance(data["top_level_entities"], list) and isinstance(data["entity_relationships"], list):
    #     # è·å–ç°æœ‰å…³ç³»ä¸­å·²å­˜åœ¨çš„(è‚¡ä¸œ->æ ¸å¿ƒå…¬å¸)å¯¹
    #     existing_relationships = set()
    #     for rel in data["entity_relationships"]:
    #         rel_from = rel.get("from", "")
    #         rel_to = rel.get("to", "")
    #         if rel_to == data["core_company"]:
    #             existing_relationships.add(rel_from)
    #     
    #     # ä¸ºé¡¶çº§ä¸ªäººè‚¡ä¸œåˆ›å»ºè‚¡æƒå…³ç³»
    #     for entity in data["top_level_entities"]:
    #         entity_name = entity.get("name", "")
    #         entity_type = entity.get("entity_type", "")
    #         percentage = entity.get("percentage", 0)
    #         
    #         # åªå¤„ç†æœ‰åç§°çš„è‚¡ä¸œï¼Œä¸”ä¸å­˜åœ¨å·²æœ‰å…³ç³»
    #         if entity_name and entity_name not in existing_relationships and percentage > 0:
    #             equity_rel = {
    #                 "from": entity_name,
    #                 "to": data["core_company"],
    #                 "relationship_type": "æŒè‚¡",
    #                 "description": f"æŒæœ‰{data['core_company']}{percentage}%çš„è‚¡æƒ"
    #             }
    #             data["entity_relationships"].append(equity_rel)
    
    # ç¡®ä¿all_entitiesåŒ…å«æ‰€æœ‰top_level_entities
    if not data["all_entities"] and data["top_level_entities"]:
        data["all_entities"] = data["top_level_entities"].copy()
    
    # ğŸ”¥ å–æ¶ˆè‡ªåŠ¨æ·»åŠ å®æ§äººåˆ°æ§åˆ¶å…³ç³» - è®©ç”¨æˆ·æ‰‹åŠ¨æ§åˆ¶
    # æ³¨é‡Šæ‰è‡ªåŠ¨ç”Ÿæˆæ§åˆ¶å…³ç³»çš„ä»£ç 
    # if data["actual_controller"] and data["core_company"] and isinstance(data["control_relationships"], list):
    #     # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„æ§åˆ¶å…³ç³»ï¼ˆåŒæ—¶è€ƒè™‘parent/childå’Œfrom/toä¸¤ç§æ ¼å¼ï¼‰
    #     exists = False
    #     for rel in data["control_relationships"]:
    #         # æ£€æŸ¥ä¸¤ç§æ ¼å¼çš„å…³ç³»æ˜¯å¦å·²ç»å­˜åœ¨
    #         if ((rel.get("parent") == data["actual_controller"] and 
    #              rel.get("child") == data["core_company"]) or 
    #             (rel.get("from") == data["actual_controller"] and 
    #              rel.get("to") == data["core_company"])):
    #             exists = True
    #             break
    #     
    #     # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æ·»åŠ æ–°çš„æ§åˆ¶å…³ç³»
    #     if not exists:
    #         control_rel = {
    #             "parent": data["actual_controller"],
    #             "child": data["core_company"],
    #             "relationship_type": "å®é™…æ§åˆ¶",
    #             "description": f"{data['actual_controller']}æ˜¯{data['core_company']}çš„å®é™…æ§åˆ¶äºº"
    #         }
    #         data["control_relationships"].append(control_rel)
    
    # å¦‚æœæ²¡æœ‰æ ¸å¿ƒå…¬å¸åç§°ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not data["core_company"]:
        data["core_company"] = "æœªå‘½åå…¬å¸"
    if not data["actual_controller"] and data["top_level_entities"]:
        # æ‰¾å‡ºæŒè‚¡æ¯”ä¾‹æœ€é«˜çš„å®ä½“
        max_entity = max(data["top_level_entities"], key=lambda x: x.get("percentage", 0), default=None)
        if max_entity:
            data["actual_controller"] = max_entity.get("name", "")
    
    # é¿å…é‡å¤çš„æ§è‚¡å…³ç³»ï¼šæ£€æŸ¥control_relationshipsä¸­æ˜¯å¦å­˜åœ¨ä¸subsidiariesé‡å¤çš„æ§è‚¡å…³ç³»
    if "control_relationships" in data and "subsidiaries" in data and isinstance(data["control_relationships"], list):
        # åˆ›å»ºå­å…¬å¸åç§°é›†åˆï¼Œç”¨äºå¿«é€Ÿæ£€æŸ¥
        subsidiary_names = set()
        for sub in data["subsidiaries"]:
            if sub.get("name"):
                subsidiary_names.add(sub.get("name").strip())
        
        # è¿‡æ»¤æ‰é‡å¤çš„æ§è‚¡å…³ç³»
        filtered_relationships = []
        for rel in data["control_relationships"]:
            # è·å–å…³ç³»çš„æ¥æºå’Œç›®æ ‡ï¼ˆå…¼å®¹parent/childå’Œfrom/toä¸¤ç§æ ¼å¼ï¼‰
            rel_parent = rel.get("parent", rel.get("from", ""))
            rel_child = rel.get("child", rel.get("to", ""))
            
            # å¦‚æœæ˜¯æ ¸å¿ƒå…¬å¸å¯¹å­å…¬å¸çš„æ§è‚¡å…³ç³»ï¼Œä¸”è¯¥å­å…¬å¸å·²åœ¨subsidiariesä¸­ï¼Œåˆ™è·³è¿‡
            if (rel_parent == data["core_company"] and 
                rel_child in subsidiary_names and 
                ("æ§è‚¡" in rel.get("relationship_type", "") or "æŒæœ‰" in rel.get("relationship_type", "") or 
                 "100%" in rel.get("description", ""))):
                logger.info(f"è¿‡æ»¤æ‰é‡å¤çš„æ§è‚¡å…³ç³»: {rel_parent} -> {rel_child}")
                continue
            
            filtered_relationships.append(rel)
        
        # æ›´æ–°æ§åˆ¶å…³ç³»åˆ—è¡¨
        data["control_relationships"] = filtered_relationships
    
    return data

# è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆå®Œæ•´çš„è‚¡æƒç»“æ„åˆ†ææŠ¥å‘Š
def generate_analysis_report(result: Dict[str, Any], content_to_analyze: Optional[str] = None) -> str:
    """
    ç”ŸæˆåŒ…å«æ ¸å¿ƒå…¬å¸ã€å®é™…æ§åˆ¶äººã€è‚¡ä¸œã€å­å…¬å¸ã€å…³è”å…³ç³»åŠæ€»ç»“çš„å®Œæ•´æŠ¥å‘Š
    
    Args:
        result: åˆ†æç»“æœæ•°æ®
        content_to_analyze: ç”¨äºåˆ†æçš„åŸå§‹å†…å®¹
        
    Returns:
        æ ¼å¼åŒ–çš„åˆ†ææŠ¥å‘Šæ–‡æœ¬
    """
    report_sections = []
    
    # ä¸€ã€åŸºæœ¬ä¿¡æ¯
    core_company = result.get('core_company', 'æœªå‘½åå…¬å¸')
    report_sections.append(f"ä¸€ã€åŸºæœ¬ä¿¡æ¯")
    report_sections.append(f"æ ¸å¿ƒå…¬å¸ï¼š{core_company}")
    
    # è·å–å®é™…æ§åˆ¶äººä¿¡æ¯
    controller_info = identify_actual_controller(result)
    controller_name = controller_info.get('name', 'æœªæ˜ç¡®')
    controller_reason = controller_info.get('reason', '')
    report_sections.append(f"å®é™…æ§åˆ¶äººï¼š{controller_name}")
    if controller_reason:
        report_sections.append(f"ç¡®è®¤ä¾æ®ï¼š{controller_reason}")
    report_sections.append("")
    
    # äºŒã€è‚¡ä¸œç»“æ„æ¦‚è§ˆ
    shareholders = result.get('shareholders', result.get('top_level_entities', []))
    report_sections.append(f"äºŒã€è‚¡ä¸œç»“æ„æ¦‚è§ˆ")
    report_sections.append(f"è‚¡ä¸œæ€»æ•°ï¼š{len(shareholders)}å")
    
    # è®¡ç®—è‡ªç„¶äººè‚¡ä¸œå’Œæ³•äººè‚¡ä¸œæ•°é‡
    natural_persons = [s for s in shareholders if s.get('type') == 'person' or 'è‡ªç„¶äºº' in str(s.get('description', ''))]
    legal_persons = [s for s in shareholders if s not in natural_persons]
    report_sections.append(f"å…¶ä¸­ï¼šè‡ªç„¶äººè‚¡ä¸œ{len(natural_persons)}åï¼Œæ³•äººè‚¡ä¸œ{len(legal_persons)}å")
    report_sections.append("")
    
    # ä¸‰ã€ä¸»è¦è‚¡ä¸œåŠå…¶æŒè‚¡æ¯”ä¾‹
    report_sections.append(f"ä¸‰ã€ä¸»è¦è‚¡ä¸œåŠå…¶æŒè‚¡æ¯”ä¾‹")
    if shareholders:
        # æŒ‰æŒè‚¡æ¯”ä¾‹é™åºæ’åº
        sorted_shareholders = sorted(shareholders, key=lambda x: x.get('percentage', 0), reverse=True)
        
        # æ˜¾ç¤ºä¸»è¦è‚¡ä¸œï¼ˆæ˜¾ç¤ºå‰5åï¼‰
        for i, shareholder in enumerate(sorted_shareholders[:5]):
            name = shareholder.get('name', 'æœªçŸ¥')
            percentage = shareholder.get('percentage', 0)
            entity_type = "è‡ªç„¶äºº" if shareholder in natural_persons else "æ³•äºº"
            report_sections.append(f"{i+1}. {name}ï¼ˆ{entity_type}ï¼‰ï¼š{percentage}%")
        
        # å¦‚æœæœ‰æ›´å¤šè‚¡ä¸œï¼Œæ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
        if len(sorted_shareholders) > 5:
            other_percentage = sum(s.get('percentage', 0) for s in sorted_shareholders[5:])
            report_sections.append(f"6. å…¶ä»–è‚¡ä¸œï¼ˆå…±{len(sorted_shareholders) - 5}åï¼‰ï¼šåˆè®¡{other_percentage:.2f}%")
    else:
        report_sections.append("æœªè·å–åˆ°è‚¡ä¸œä¿¡æ¯")
    report_sections.append("")
    
    # å››ã€å­å…¬å¸å…³ç³»
    subsidiaries = result.get('subsidiaries', [])
    report_sections.append(f"å››ã€å­å…¬å¸å…³ç³»")
    if subsidiaries:
        report_sections.append(f"å­å…¬å¸æ€»æ•°ï¼š{len(subsidiaries)}å®¶")
        
        # æ˜¾ç¤ºä¸»è¦å­å…¬å¸ï¼ˆå‰5å®¶ï¼‰
        for i, subsidiary in enumerate(subsidiaries[:5]):
            name = subsidiary.get('name', 'æœªçŸ¥')
            percentage = subsidiary.get('percentage', 0)
            report_sections.append(f"{i+1}. {name}ï¼šæŒè‚¡{percentage}%")
        
        # å¦‚æœæœ‰æ›´å¤šå­å…¬å¸ï¼Œæ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
        if len(subsidiaries) > 5:
            report_sections.append(f"... ç­‰{len(subsidiaries) - 5}å®¶å­å…¬å¸")
    else:
        report_sections.append("æœªè·å–åˆ°å­å…¬å¸ä¿¡æ¯")
    report_sections.append("")
    
    # äº”ã€æ§åˆ¶å…³ç³»åˆ†æ
    control_relationships = result.get('control_relationships', [])
    report_sections.append(f"äº”ã€æ§åˆ¶å…³ç³»åˆ†æ")
    if control_relationships:
        report_sections.append(f"æ§åˆ¶å…³ç³»æ•°é‡ï¼š{len(control_relationships)}æ¡")
        
        # æ˜¾ç¤ºå…³é”®æ§åˆ¶å…³ç³»
        for rel in control_relationships[:5]:
            parent = rel.get('parent', rel.get('from', 'æœªçŸ¥'))
            child = rel.get('child', rel.get('to', 'æœªçŸ¥'))
            desc = rel.get('description', 'æ§åˆ¶å…³ç³»')
            report_sections.append(f"- {parent} â†’ {child}ï¼š{desc}")
    else:
        report_sections.append("æœªè·å–åˆ°æ˜ç¡®çš„æ§åˆ¶å…³ç³»ä¿¡æ¯")
    report_sections.append("")
    
    # å…­ã€è‚¡æƒç»“æ„æ€»ç»“
    report_sections.append(f"å…­ã€è‚¡æƒç»“æ„æ€»ç»“")
    summary = generate_summary(result)
    report_sections.append(summary)
    
    return "\n".join(report_sections)

# è¾…åŠ©å‡½æ•°ï¼šè¯†åˆ«å®é™…æ§åˆ¶äºº
def identify_actual_controller(result: Dict[str, Any]) -> Dict[str, str]:
    """
    åŸºäºæŒè‚¡æ¯”ä¾‹è¯†åˆ«å®é™…æ§åˆ¶äºº
    
    Args:
        result: åˆ†æç»“æœæ•°æ®
        
    Returns:
        åŒ…å«å®é™…æ§åˆ¶äººåç§°å’Œç¡®è®¤ä¾æ®çš„å­—å…¸
    """
    shareholders = result.get('shareholders', result.get('top_level_entities', []))
    core_company = result.get('core_company', 'ç›®æ ‡å…¬å¸')
    
    # å¦‚æœç»“æœä¸­å·²ç»æœ‰å®é™…æ§åˆ¶äººä¿¡æ¯ï¼Œç›´æ¥è¿”å›
    if 'actual_controller' in result and result['actual_controller']:
        return {
            "name": result['actual_controller'],
            "reason": f"æ ¹æ®åˆ†æç»“æœç›´æ¥ç¡®è®¤{result['actual_controller']}ä¸ºå®é™…æ§åˆ¶äºº"
        }
    
    if not shareholders:
        return {"name": "æœªæ˜ç¡®", "reason": "æ— è‚¡ä¸œä¿¡æ¯å¯ç”¨äºåˆ¤æ–­å®é™…æ§åˆ¶äºº"}
    
    # æŒ‰æŒè‚¡æ¯”ä¾‹é™åºæ’åº
    sorted_shareholders = sorted(shareholders, key=lambda x: x.get('percentage', 0), reverse=True)
    top_shareholder = sorted_shareholders[0]
    top_percentage = top_shareholder.get('percentage', 0)
    
    # åˆ¤æ–­æ§åˆ¶ç±»å‹
    if top_percentage > 50:
        return {
            "name": top_shareholder.get('name', 'æœªçŸ¥'),
            "reason": f"ç›´æ¥æŒæœ‰å…¬å¸{top_percentage}%çš„è‚¡ä»½ï¼ŒæŒè‚¡æ¯”ä¾‹è¶…è¿‡50%ï¼Œå¯¹å…¬å¸æ‹¥æœ‰ç»å¯¹æ§è‚¡æƒ"
        }
    elif len(sorted_shareholders) >= 2 and top_percentage > sorted_shareholders[1].get('percentage', 0) * 2:
        second_percentage = sorted_shareholders[1].get('percentage', 0)
        return {
            "name": top_shareholder.get('name', 'æœªçŸ¥'),
            "reason": f"æŒæœ‰{top_percentage}%çš„è‚¡ä»½ï¼Œæ˜¯ç¬¬äºŒå¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹ï¼ˆ{second_percentage}%ï¼‰çš„ä¸¤å€ä»¥ä¸Šï¼Œç›¸å¯¹æ§è‚¡åœ°ä½æ˜æ˜¾"
        }
    elif len(sorted_shareholders) >= 3 and top_percentage > sum(s.get('percentage', 0) for s in sorted_shareholders[1:3]):
        second_third_percentage = sum(s.get('percentage', 0) for s in sorted_shareholders[1:3])
        return {
            "name": top_shareholder.get('name', 'æœªçŸ¥'),
            "reason": f"æŒæœ‰{top_percentage}%çš„è‚¡ä»½ï¼Œè¶…è¿‡ç¬¬äºŒã€ä¸‰å¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹ä¹‹å’Œï¼ˆ{second_third_percentage}%ï¼‰ï¼Œç›¸å¯¹æ§è‚¡"
        }
    else:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„æ§åˆ¶å…³ç³»
        control_relationships = result.get('control_relationships', [])
        for rel in control_relationships:
            if rel.get('child') == core_company or rel.get('to') == core_company:
                controller = rel.get('parent', rel.get('from', 'æœªçŸ¥'))
                return {
                    "name": controller,
                    "reason": f"é€šè¿‡æ§åˆ¶å…³ç³»ç¡®è®¤{controller}å¯¹{core_company}å…·æœ‰æ§åˆ¶æƒ"
                }
        
        return {
            "name": top_shareholder.get('name', 'æœªçŸ¥'),
            "reason": f"æŒæœ‰{top_percentage}%çš„è‚¡ä»½ï¼Œä¸ºç¬¬ä¸€å¤§è‚¡ä¸œï¼Œä½†æŒè‚¡æ¯”ä¾‹ä¸é«˜ï¼Œå¯èƒ½å­˜åœ¨å…±åŒæ§åˆ¶æˆ–æ— å®é™…æ§åˆ¶äººæƒ…å†µ"
        }

# è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆè‚¡æƒç»“æ„æ€»ç»“
def generate_summary(result: Dict[str, Any]) -> str:
    """
    ç”Ÿæˆè‚¡æƒç»“æ„æ€»ç»“
    
    Args:
        result: åˆ†æç»“æœæ•°æ®
        
    Returns:
        è‚¡æƒç»“æ„æ€»ç»“æ–‡æœ¬
    """
    core_company = result.get('core_company', 'ç›®æ ‡å…¬å¸')
    shareholders = result.get('shareholders', result.get('top_level_entities', []))
    subsidiaries = result.get('subsidiaries', [])
    
    if not shareholders:
        return f"{core_company}è‚¡æƒç»“æ„ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•æä¾›æœ‰æ•ˆåˆ†æã€‚"
    
    # è®¡ç®—å‰ä¸‰å¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹
    sorted_shareholders = sorted(shareholders, key=lambda x: x.get('percentage', 0), reverse=True)
    top_3_percentage = sum(s.get('percentage', 0) for s in sorted_shareholders[:3])
    
    # åˆ¤æ–­è‚¡æƒé›†ä¸­åº¦
    if top_3_percentage > 70:
        concentration = "è‚¡æƒé«˜åº¦é›†ä¸­"
    elif top_3_percentage > 50:
        concentration = "è‚¡æƒç›¸å¯¹é›†ä¸­"
    else:
        concentration = "è‚¡æƒè¾ƒä¸ºåˆ†æ•£"
    
    # è·å–å®é™…æ§åˆ¶äººä¿¡æ¯
    controller_info = identify_actual_controller(result)
    controller_name = controller_info.get('name', 'æœªçŸ¥')
    
    # æ„å»ºæ€»ç»“
    summary = f"{core_company}{concentration}ï¼Œ{controller_name}"
    
    if top_3_percentage > 50:
        summary += f"å¤„äºç›¸å¯¹æ§è‚¡åœ°ä½ï¼Œå‰ä¸‰å¤§è‚¡ä¸œåˆè®¡æŒè‚¡çº¦{top_3_percentage:.2f}%ï¼Œæ§åˆ¶æƒè¾ƒä¸ºç¨³å®š"
    else:
        summary += f"ä¸ºä¸»è¦è‚¡ä¸œï¼Œå‰ä¸‰å¤§è‚¡ä¸œåˆè®¡æŒè‚¡çº¦{top_3_percentage:.2f}%ï¼Œå¯èƒ½å­˜åœ¨è‚¡æƒåˆ¶è¡¡å…³ç³»"
    
    if subsidiaries:
        summary += f"ã€‚å…¬å¸æ‹¥æœ‰{len(subsidiaries)}å®¶å­å…¬å¸ï¼Œå½¢æˆä¸€å®šè§„æ¨¡çš„ä¼ä¸šé›†å›¢ç»“æ„"
    
    summary += "ã€‚å»ºè®®å…³æ³¨å…¬å¸ç« ç¨‹ä¸­å…³äºé‡å¤§äº‹é¡¹è¡¨å†³æœºåˆ¶çš„è§„å®šï¼Œä»¥åŠæ˜¯å¦å­˜åœ¨ä¸€è‡´è¡ŒåŠ¨åè®®ç­‰ç‰¹æ®Šå®‰æ’ï¼Œè¿™äº›å› ç´ å¯èƒ½å¯¹å…¬å¸å®é™…æ§åˆ¶æƒäº§ç”Ÿé‡è¦å½±å“ã€‚"
    
    return summary

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    test_prompt = "è¯·åˆ†æè¿™å®¶å…¬å¸çš„è‚¡æƒç»“æ„ï¼Œç‰¹åˆ«å…³æ³¨æ§è‚¡å…³ç³»å’Œè™šæ‹Ÿå…³ç³»"
    result, errors = analyze_equity_with_ai(test_prompt)
    print("åˆ†æç»“æœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    if errors:
        print("\né”™è¯¯æ—¥å¿—:")
        for error in errors:
            print(f"- {error}")